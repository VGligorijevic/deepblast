{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will show an example of how to run deepblast on simulation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepblast.sim import hmm_alignments\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first simulate multiple sequences from a single PFam family.\n",
    "The resulting generated alignments will be used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = '../data/zf-C2H2.hmm'\n",
    "n_alignments = 100\n",
    "np.random.seed(0)\n",
    "align_df = hmm_alignments(n=40, seed=0, n_alignments=n_alignments, hmmfile=hmm)\n",
    "\n",
    "cols = [\n",
    "    'chain1_name', 'chain2_name', 'tmscore1', 'tmscore2', 'rmsd',\n",
    "    'chain1', 'chain2', 'alignment'\n",
    "]\n",
    "align_df.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulated alignments will be split into training / testing and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = n_alignments // 10\n",
    "train_df = align_df.iloc[:parts * 8]\n",
    "test_df = align_df.iloc[parts * 8:parts * 9]\n",
    "valid_df = align_df.iloc[parts * 9:]\n",
    "\n",
    "# save the files to disk.\n",
    "train_df.to_csv('data/train.txt', sep='\\t', index=None, header=None)\n",
    "test_df.to_csv('data/test.txt', sep='\\t', index=None, header=None)\n",
    "valid_df.to_csv('data/valid.txt', sep='\\t', index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will prepare the environment to make sure that the appropriate output directories exist to store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.trainer import LightningAligner\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "output_dir = 'simulation_results'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/juermieboop/Documents/research/garfunkel/ipynb'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create the arguments.  Below is the way to create this in a python environment.\n",
    "This can also be recreated on a standard command line interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\n",
    "    '--train-pairs', f'{os.getcwd()}/data/train.txt',\n",
    "    '--test-pairs', f'{os.getcwd()}/data/test.txt',\n",
    "    '--valid-pairs', f'{os.getcwd()}/data/valid.txt',\n",
    "    '--output-directory', output_dir,\n",
    "    '--epochs', '128',\n",
    "    '--batch-size', '1',   \n",
    "    '--num-workers', '27',\n",
    "    '--learning-rate', '5e-5',\n",
    "    '--layers', '2',\n",
    "    '--visualization-fraction', '1',\n",
    "    '--loss', 'cross_entropy',\n",
    "    '--scheduler', 'none',\n",
    "    '--gpus', '1'\n",
    "]\n",
    "parser = argparse.ArgumentParser(add_help=False)\n",
    "parser = LightningAligner.add_model_specific_args(parser)\n",
    "parser.add_argument('--num-workers', type=int)\n",
    "parser.add_argument('--gpus', type=int)\n",
    "args = parser.parse_args(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then initialize the alignment model with the parameters we specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightningAligner(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                   | Params\n",
      "---------------------------------------------------\n",
      "0 | aligner | NeedlemanWunschAligner | 34 M  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5beafedfb442f3af2527fbd29e817b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=args.epochs,\n",
    "    gpus=args.gpus,\n",
    "    check_val_every_n_epoch=10,\n",
    "    # profiler=profiler,\n",
    "    fast_dev_run=False,\n",
    "    # auto_scale_batch_size='power'\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model diagnostics can be directly visualized in Tensorboard. Here, we show the losses, the accuracy and the alignment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we did this with just a few million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls lightning_logs/version_68/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "checkpoint_dir = 'lightning_logs/version_68/checkpoints'\n",
    "path = f'{checkpoint_dir}/epoch=49.ckpt'\n",
    "model = LightningAligner.load_from_checkpoint(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.dataset.dataset import states2matrix, tmstate_f\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test = align_df\n",
    "x = str.encode(test.iloc[i]['chain1'])\n",
    "y = str.encode(test.iloc[i]['chain2'])\n",
    "states = test.iloc[i]['alignment']\n",
    "x_ = torch.Tensor(model.tokenizer(x)).long().unsqueeze(0)\n",
    "y_ = torch.Tensor(model.tokenizer(y)).long().unsqueeze(0)\n",
    "x_ = pack_sequence(x_, enforce_sorted=False).cuda()\n",
    "y_ = pack_sequence(y_, enforce_sorted=False).cuda()\n",
    "states = list(map(tmstate_f, states))\n",
    "A = states2matrix(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "aln, theta, gap = model.forward(x_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(16, 3))\n",
    "sns.heatmap(A, ax=ax[0])\n",
    "sns.heatmap(aln.cpu().detach().numpy().squeeze(), ax=ax[1])\n",
    "sns.heatmap(np.log(theta.cpu().detach().numpy().squeeze()), ax=ax[2])\n",
    "sns.heatmap(gap.cpu().detach().numpy().squeeze(), ax=ax[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.dataset.alphabet import Uniprot21\n",
    "from deepblast.dataset.dataset import decode\n",
    "from deepblast.score import alignment_text, roc_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.dataset.dataset import states2edges\n",
    "\n",
    "#pred_edges = list(zip(pred_y, pred_x))\n",
    "pred_edges = states2edges(pred_states)\n",
    "true_edges = states2edges(truth_states)\n",
    "stats = roc_edges(true_edges, pred_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = model.aligner.traceback(x_, y_)\n",
    "decoded, _ = next(gen)\n",
    "pred_x, pred_y, pred_states = list(zip(*decoded))\n",
    "pred_states = np.array(list(pred_states))\n",
    "truth_states = np.array(list(states))                    \n",
    "text = alignment_text(x.decode('utf-8'), y.decode('utf-8'), pred_states, truth_states, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px, py = zip(*pred_edges)\n",
    "tx, ty = zip(*true_edges)\n",
    "\n",
    "plt.plot(px, py, label='pred')\n",
    "plt.plot(tx, ty, label='truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.dataset.dataset import state_diff_f\n",
    "def states2edges(states):\n",
    "    \"\"\" Converts state string to bipartite matching. \"\"\"\n",
    "    prev_s, next_s = states[:-1], states[1:]\n",
    "    transitions = list(zip(prev_s, next_s))\n",
    "    state_diffs = np.array(list(map(state_diff_f, transitions)))\n",
    "    coords = np.cumsum(state_diffs, axis=0).tolist()\n",
    "    coords = [(0, 0)] + list(map(tuple, coords))\n",
    "    return coords\n",
    "pe = states2edges(list(pred_states))\n",
    "te = states2edges(list(truth_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px, py = zip(*pe)\n",
    "tx, ty = zip(*te)\n",
    "\n",
    "plt.plot(px, py, label='pred')\n",
    "plt.plot(tx, ty, label='truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

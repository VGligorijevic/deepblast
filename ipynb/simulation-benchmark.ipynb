{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will show an example of how to run deepblast on simulation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepblast.sim import hmm_alignments\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first simulate multiple sequences from a single PFam family.\n",
    "The resulting generated alignments will be used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = '../data/zf-C2H2.hmm'\n",
    "n_alignments = 100\n",
    "np.random.seed(0)\n",
    "align_df = hmm_alignments(n=40, seed=0, n_alignments=n_alignments, hmmfile=hmm)\n",
    "\n",
    "cols = [\n",
    "    'chain1_name', 'chain2_name', 'tmscore1', 'tmscore2', 'rmsd',\n",
    "    'chain1', 'chain2', 'alignment'\n",
    "]\n",
    "align_df.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulated alignments will be split into training / testing and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = n_alignments // 10\n",
    "train_df = align_df.iloc[:parts * 8]\n",
    "test_df = align_df.iloc[parts * 8:parts * 9]\n",
    "valid_df = align_df.iloc[parts * 9:]\n",
    "\n",
    "# save the files to disk.\n",
    "train_df.to_csv('data/train.txt', sep='\\t', index=None, header=None)\n",
    "test_df.to_csv('data/test.txt', sep='\\t', index=None, header=None)\n",
    "valid_df.to_csv('data/valid.txt', sep='\\t', index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will prepare the environment to make sure that the appropriate output directories exist to store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.trainer import LightningAligner\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "output_dir = 'simulation_results'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/juermieboop/Documents/research/garfunkel/ipynb'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create the arguments.  Below is the way to create this in a python environment.\n",
    "This can also be recreated on a standard command line interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\n",
    "    '--train-pairs', f'{os.getcwd()}/data/train.txt',\n",
    "    '--test-pairs', f'{os.getcwd()}/data/test.txt',\n",
    "    '--valid-pairs', f'{os.getcwd()}/data/valid.txt',\n",
    "    '--output-directory', output_dir,\n",
    "    '--epochs', '15',\n",
    "    '--batch-size', '10',   \n",
    "    '--num-workers', '1',\n",
    "    '--learning-rate', '1e-5',\n",
    "    '--layers', '2',\n",
    "    '--visualization-fraction', '1',\n",
    "    '--loss', 'cross_entropy',\n",
    "    '--scheduler', 'none',\n",
    "    '--gpus', '1'\n",
    "]\n",
    "parser = argparse.ArgumentParser(add_help=False)\n",
    "parser = LightningAligner.add_model_specific_args(parser)\n",
    "parser.add_argument('--num-workers', type=int)\n",
    "parser.add_argument('--gpus', type=int)\n",
    "args = parser.parse_args(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then initialize the alignment model with the parameters we specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightningAligner(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                   | Params\n",
      "---------------------------------------------------\n",
      "0 | aligner | NeedlemanWunschAligner | 34 M  \n",
      "/home/juermieboop/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/juermieboop/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d34dfe8a3ff48b89c0ecd897e9bef44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=args.epochs,\n",
    "    gpus=args.gpus,\n",
    "    check_val_every_n_epoch=10,\n",
    "    # profiler=profiler,\n",
    "    fast_dev_run=False,\n",
    "    # auto_scale_batch_size='power'\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model diagnostics can be directly visualized in Tensorboard. Here, we show the losses, the accuracy and the alignment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_0    version_16  version_33  version_50  version_68  version_85\r\n",
      "version_1    version_17  version_34  version_51  version_69  version_86\r\n",
      "version_10   version_18  version_35  version_52  version_7   version_87\r\n",
      "version_100  version_19  version_36  version_53  version_70  version_88\r\n",
      "version_101  version_2\t version_37  version_54  version_71  version_89\r\n",
      "version_102  version_20  version_38  version_55  version_72  version_9\r\n",
      "version_103  version_21  version_39  version_56  version_73  version_90\r\n",
      "version_104  version_22  version_4   version_57  version_74  version_91\r\n",
      "version_105  version_23  version_40  version_58  version_75  version_92\r\n",
      "version_106  version_24  version_41  version_59  version_76  version_93\r\n",
      "version_107  version_25  version_42  version_6\t version_77  version_94\r\n",
      "version_108  version_26  version_43  version_60  version_78  version_95\r\n",
      "version_109  version_27  version_44  version_61  version_79  version_96\r\n",
      "version_11   version_28  version_45  version_62  version_8   version_97\r\n",
      "version_110  version_29  version_46  version_63  version_80  version_98\r\n",
      "version_12   version_3\t version_47  version_64  version_81  version_99\r\n",
      "version_13   version_30  version_48  version_65  version_82\r\n",
      "version_14   version_31  version_49  version_66  version_83\r\n",
      "version_15   version_32  version_5   version_67  version_84\r\n"
     ]
    }
   ],
   "source": [
    "!ls lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 4355), started 9:57:10 ago. (Use '!kill 4355' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e15ef51c9f244edc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e15ef51c9f244edc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we did this with just a few million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeedlemanWunschAligner(\n",
       "  (lm): BiLM(\n",
       "    (embed): Embedding(22, 21, padding_idx=21)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (rnn): ModuleList(\n",
       "      (0): LSTM(21, 1024, batch_first=True)\n",
       "      (1): LSTM(1024, 1024, batch_first=True)\n",
       "    )\n",
       "    (linear): Linear(in_features=1024, out_features=21, bias=True)\n",
       "  )\n",
       "  (match_embedding): StackedRNN(\n",
       "    (embed): Embedding(21, 512, padding_idx=20)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (rnn): LSTM(512, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "    (proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (gap_embedding): StackedRNN(\n",
       "    (embed): Embedding(21, 512, padding_idx=20)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (rnn): LSTM(512, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "    (proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (nw): NeedlemanWunschDecoder()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'epoch=59.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "!ls lightning_logs/version_70/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "checkpoint_dir = 'lightning_logs/version_70/checkpoints'\n",
    "path = f'{checkpoint_dir}/epoch=59.ckpt'\n",
    "model = LightningAligner.load_from_checkpoint(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.dataset.dataset import states2matrix, tmstate_f\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 9\n",
    "test = align_df\n",
    "x = str.encode(test.iloc[i]['chain1'])\n",
    "y = str.encode(test.iloc[i]['chain2'])\n",
    "states = test.iloc[i]['alignment']\n",
    "x_ = torch.Tensor(model.tokenizer(x)).long().unsqueeze(0)\n",
    "y_ = torch.Tensor(model.tokenizer(y)).long().unsqueeze(0)\n",
    "x_ = pack_sequence(x_, enforce_sorted=False).cuda()\n",
    "y_ = pack_sequence(y_, enforce_sorted=False).cuda()\n",
    "states = list(map(tmstate_f, states))\n",
    "A = states2matrix(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-29046d1e12ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maln\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/research/garfunkel/deepblast/trainer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maligner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/research/garfunkel/deepblast/alignment.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, order)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\"\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mzx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mgx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgap_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/research/garfunkel/deepblast/dataset/utils.py\u001b[0m in \u001b[0;36munpack_sequences\u001b[0;34m(x, order)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mlookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0mseqlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/research/garfunkel/deepblast/dataset/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mlookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0mseqlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "aln, theta, gap = model.forward(x_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(16, 3))\n",
    "sns.heatmap(A, ax=ax[0])\n",
    "sns.heatmap(aln.cpu().detach().numpy().squeeze(), ax=ax[1])\n",
    "sns.heatmap(np.log(theta.cpu().detach().numpy().squeeze()), ax=ax[2])\n",
    "sns.heatmap(gap.cpu().detach().numpy().squeeze(), ax=ax[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.dataset.alphabet import Uniprot21\n",
    "from deepblast.dataset.dataset import decode\n",
    "from deepblast.score import alignment_text, roc_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.dataset.dataset import states2edges\n",
    "\n",
    "#pred_edges = list(zip(pred_y, pred_x))\n",
    "pred_edges = states2edges(pred_states)\n",
    "true_edges = states2edges(truth_states)\n",
    "stats = roc_edges(true_edges, pred_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = model.aligner.traceback(x_, y_)\n",
    "decoded, _ = next(gen)\n",
    "pred_x, pred_y, pred_states = list(zip(*decoded))\n",
    "pred_states = np.array(list(pred_states))\n",
    "truth_states = np.array(list(states))                    \n",
    "text = alignment_text(x.decode('utf-8'), y.decode('utf-8'), pred_states, truth_states, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px, py = zip(*pred_edges)\n",
    "tx, ty = zip(*true_edges)\n",
    "\n",
    "plt.plot(px, py, label='pred')\n",
    "plt.plot(tx, ty, label='truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepblast.dataset.dataset import state_diff_f\n",
    "def states2edges(states):\n",
    "    \"\"\" Converts state string to bipartite matching. \"\"\"\n",
    "    prev_s, next_s = states[:-1], states[1:]\n",
    "    transitions = list(zip(prev_s, next_s))\n",
    "    state_diffs = np.array(list(map(state_diff_f, transitions)))\n",
    "    coords = np.cumsum(state_diffs, axis=0).tolist()\n",
    "    coords = [(0, 0)] + list(map(tuple, coords))\n",
    "    return coords\n",
    "pe = states2edges(list(pred_states))\n",
    "te = states2edges(list(truth_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px, py = zip(*pe)\n",
    "tx, ty = zip(*te)\n",
    "\n",
    "plt.plot(px, py, label='pred')\n",
    "plt.plot(tx, ty, label='truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

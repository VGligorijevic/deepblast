#!/usr/bin/env python3

import argparse
import os

import torch
from deepblast.trainer import LightningAligner


def main(args):
    print('args', args)
    model = LightningAligner.load_from_checkpoint(
        args.load_from_checkpoint)

    trainer = Trainer(
        max_epochs=args.epochs,
        gpus=args.gpus,
        num_nodes=args.nodes,
        accumulate_grad_batches=args.grad_accum,
        gradient_clip_val=args.grad_clip,

        distributed_backend=args.backend,
        precision=args.precision,
        # check_val_every_n_epoch=1,
        val_check_interval=0.25,
        fast_dev_run=False,
        # auto_scale_batch_size='power',
        # profiler=profiler,
    )
    trainer.test()


if __name__ == '__main__':
    parser = argparse.ArgumentParser(add_help=False)
    parser.add_argument('--gpus', type=int, default=None)
    parser.add_argument('--num-workers', type=int, default=1)
    parser.add_argument('--load-from-checkpoint', type=str, default=None)
    # options include ddp_cpu, dp, ddp

    parser = LightningAligner.add_model_specific_args(parser)
    hparams = parser.parse_args()
    main(hparams)
